{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import h5py \n","import numpy as np\n","import os\n","from nlb_tools.nwb_interface import NWBDataset\n","from nlb_tools.make_tensors import make_train_input_tensors, make_eval_input_tensors, make_eval_target_tensors, save_to_h5\n","from nlb_tools.evaluation import evaluate\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_dict = {\n","    '000128': 'mc_maze',\n","    '000127': 'area2_bump',\n","    '000130': 'dmfc_rsg',\n","    '000129': 'mc_rtt',\n","    '000138': 'mc_maze_large'\n","}\n","data_list = os.listdir('./data')\n","sP = './data/h5'\n","# for idx in ['000128', '000127', '000130', '000129', '000138']:\n","idx = '000128'\n","dataset_name = dataset_dict[idx]\n","print('==========' + dataset_name + '==========')\n","for d in data_list:\n","    if d.split('_')[0]==idx:\n","        if d.split('_')[2]=='desc-test':\n","            fn_tes = os.path.join('./data', d)\n","        elif d.split('_')[2]=='desc-train':\n","            fn = os.path.join('./data', d)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bin_width = 5\n","dataset = NWBDataset(fn)\n","dataset_tes = NWBDataset(fn_tes)\n","dataset.resample(bin_width)\n","dataset_tes.resample(bin_width)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ## Make train input data\n","# # Generate input tensors\n","train_dict = make_train_input_tensors(dataset, dataset_name=dataset_name, trial_split='train', save_path=os.path.join(sP, idx+\"_train_input.h5\"), save_file=True, include_forward_pred=True)\n","# ## Make eval input data\n","# # Generate input tensors\n","eval_dict = make_eval_input_tensors(dataset, dataset_name=dataset_name, trial_split='val', save_path=os.path.join(sP, idx+\"_eval_input.h5\"), save_file=True)\n","# ## Make test input data\n","# # Generate input tensors\n","test_dict = make_eval_input_tensors(dataset_tes, dataset_name=dataset_name, trial_split='test', save_path=os.path.join(sP, idx+\"_test_input.h5\"), save_file=True)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["target_dict = make_eval_target_tensors(dataset, dataset_name, 'train', 'val', save_file=True, save_path=os.path.join(sP, idx+\"_target_input.h5\"), include_psth=True)\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}