{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import h5py \n","import numpy as np\n","import os\n","from nlb_tools.nwb_interface import NWBDataset\n","from nlb_tools.make_tensors import make_train_input_tensors, make_eval_input_tensors, make_eval_target_tensors, save_to_h5\n","from nlb_tools.evaluation import evaluate"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["==========mc_maze==========\n"]}],"source":["dataset_dict = {\n","    '000128': 'mc_maze',\n","    '000127': 'area2_bump',\n","    '000130': 'dmfc_rsg',\n","    '000129': 'mc_rtt',\n","    '000138': 'mc_maze_large'\n","}\n","data_list = os.listdir('./data')\n","sP = './data/h5'\n","# for idx in ['000128', '000127', '000130', '000129', '000138']:\n","idx = '000128'\n","dataset_name = dataset_dict[idx]\n","print('==========' + dataset_name + '==========')\n","for d in data_list:\n","    if d.split('_')[0]==idx:\n","        if d.split('_')[2]=='desc-test':\n","            fn_tes = os.path.join('./data', d)\n","        elif d.split('_')[2]=='desc-train':\n","            fn = os.path.join('./data', d)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["bin_width = 5\n","dataset = NWBDataset(fn)\n","dataset_tes = NWBDataset(fn_tes)\n","dataset.resample(bin_width)\n","dataset_tes.resample(bin_width)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# ## Make train input data\n","# # Generate input tensors\n","train_dict = make_train_input_tensors(dataset, dataset_name=dataset_name, trial_split='train', save_path=os.path.join(sP, idx+\"_train_input.h5\"), save_file=False, include_forward_pred=True)\n","# ## Make eval input data\n","# # Generate input tensors\n","eval_dict = make_eval_input_tensors(dataset, dataset_name=dataset_name, trial_split='val', save_path=os.path.join(sP, idx+\"_eval_input.h5\"), save_file=False)\n","# ## Make test input data\n","# # Generate input tensors\n","test_dict = make_eval_input_tensors(dataset_tes, dataset_name=dataset_name, trial_split='test', save_path=os.path.join(sP, idx+\"_test_input.h5\"), save_file=False)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["target_dict = make_eval_target_tensors(dataset, dataset_name, 'train', 'val', save_file=False, save_path=os.path.join(sP, idx+\"_target_input.h5\"), include_psth=True)\n"]}],"metadata":{"interpreter":{"hash":"ace6faa92082bcf39b13832235d8cfc943222f9017d6df106d112a19597cfb15"},"kernelspec":{"display_name":"Python 3.8.2 ('3.8.2-venv')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
