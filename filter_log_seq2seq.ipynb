{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Import Packages"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import time\n","import os\n","from scipy.ndimage import gaussian_filter1d\n","from nlb_tools.make_tensors import h5_to_dict, save_to_h5\n","from nlb_tools.evaluation import evaluate\n","import h5py"]},{"cell_type":"markdown","metadata":{},"source":["## GPU Setting"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["tStart = time.time()\n","print(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "]},{"cell_type":"markdown","metadata":{},"source":["## Sub Functions"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def _GF(ddd, sig, N, C, log=True):\n","    TL = []\n","    for n in range(N):\n","        CL = []\n","        spike = ddd[n, :, :]\n","        for c in range(C):\n","            sp_c = spike[:, c]\n","            sp_c_gf = gaussian_filter1d(sp_c.astype(np.float32), sig)\n","            if log:\n","                CL.append(np.log(sp_c_gf + 1e-10)[:, np.newaxis])\n","            else:\n","                CL.append(sp_c_gf[:, np.newaxis])\n","        TL.append(np.hstack(CL)[np.newaxis, :, :])\n","    TL = np.vstack(TL)\n","    return TL\n","\n","def _Dict(dataset_name, train, valid, T, C):\n","    train_rates_heldin = train[:, :T, :C]\n","    train_rates_heldout = train[:, :T, C:]\n","    eval_rates_heldin = valid[:, :T, :C]\n","    eval_rates_heldout = valid[:, :T, C:]\n","    eval_rates_heldin_forward = valid[:, T:, :C]\n","    eval_rates_heldout_forward = valid[:, T:, C:]\n","\n","    output_dict = {\n","        dataset_name: {\n","            'train_rates_heldin': train_rates_heldin.astype(np.float64),\n","            'train_rates_heldout': train_rates_heldout.astype(np.float64),\n","            'eval_rates_heldin': eval_rates_heldin.astype(np.float64),\n","            'eval_rates_heldout': eval_rates_heldout.astype(np.float64),\n","            'eval_rates_heldin_forward': eval_rates_heldin_forward.astype(np.float64),\n","            'eval_rates_heldout_forward': eval_rates_heldout_forward.astype(np.float64)\n","        }\n","    }  \n","    return output_dict\n","\n","def _shuffle(spk_hi):\n","    spk_hi_shf = spk_hi[:, :, torch.randperm(spk_hi.size()[2])]\n","    return spk_hi_shf\n","\n","def _GF_pt(spk_pt, sig, N, C, log=True):\n","    spk_np = spk_pt.data.numpy()\n","    spk_GF_np = _GF(spk_np, sig, N, C, log)\n","    return torch.from_numpy(spk_GF_np).type(torch.FloatTensor)\n","\n","\n","def init_weights(m):\n","    if isinstance(m, nn.Linear):\n","        torch.nn.init.xavier_uniform_(m.weight)\n","        m.bias.data.fill_(0.01)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Create Dictionary"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==========mc_maze==========\n"]}],"source":["dataset_dict = {\n","    '000128': 'mc_maze',\n","    '000127': 'area2_bump',\n","    '000130': 'dmfc_rsg',\n","    '000129': 'mc_rtt',\n","    '000138': 'mc_maze_large'\n","}\n","hT_dict = {\n","    '000128': 7,\n","    '000127': 6,\n","    '000130': 15,\n","    '000129': 6,\n","    '000138': 7\n","}\n","sP = './inFR'\n","dpath = './data/h5'\n","data_list = os.listdir('./data/h5')\n","\n","# for idx in ['000127', '000128', '000129', '000130', '000138']:\n","idx = '000128'\n","dataset_name = dataset_dict[idx]\n","print('\\n==========' + dataset_name + '==========')\n","for d in data_list:\n","    if d.split('_')[0]==idx:\n","        if d.split('_')[1]=='train':\n","            train_F = d\n","        elif d.split('_')[1]=='eval':\n","            valid_F = d\n","        elif d.split('_')[1]=='test':\n","            test_F = d   \n","        elif d.split('_')[1]=='target':\n","            target_F = d               \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Data Processing"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["train_H5 = h5py.File(os.path.join(dpath, train_F), 'r')\n","valid_H5 = h5py.File(os.path.join(dpath, valid_F), 'r')\n","test_H5 = h5py.File(os.path.join(dpath, test_F), 'r')\n","target_dict = h5_to_dict(h5py.File(os.path.join(dpath, target_F), 'r'))\n","\n","train_spikes_heldin  = np.array(train_H5['train_spikes_heldin'])\n","train_spikes_heldin_forward  = np.array(train_H5['train_spikes_heldin_forward'])\n","train_spikes_heldout  = np.array(train_H5['train_spikes_heldout'])\n","train_spikes_heldout_forward  = np.array(train_H5['train_spikes_heldout_forward'])\n","\n","eval_spikes_heldin = np.array(valid_H5['eval_spikes_heldin'])\n","eval_spikes_heldout = np.array(valid_H5['eval_spikes_heldout'])\n","\n","test_spikes_heldin = np.array(test_H5['eval_spikes_heldin'])\n","\n","N_tra, T, C = train_spikes_heldin.shape\n","N_val = eval_spikes_heldin.shape[0]\n","N_tes = test_spikes_heldin.shape[0]\n","_, To, Co = train_spikes_heldout_forward.shape"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["train_fd = np.concatenate([train_spikes_heldin_forward, train_spikes_heldout_forward], axis=-1).astype(np.int64)\n","train_bd = np.concatenate([train_spikes_heldin, train_spikes_heldout], axis=-1).astype(np.int64)\n","train = np.concatenate([train_fd, train_bd], axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["## Time Counting"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","It cost 1.2952 sec\n"]}],"source":["tEnd = time.time()\n","print (\"\\n\" + \"It cost {:.4f} sec\" .format(tEnd-tStart))"]}],"metadata":{"interpreter":{"hash":"ace6faa92082bcf39b13832235d8cfc943222f9017d6df106d112a19597cfb15"},"kernelspec":{"display_name":"Python 3.8.2 ('3.8.2-venv')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
